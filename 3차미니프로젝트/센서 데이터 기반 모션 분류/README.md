# 데이터 분석

- 어제와 달리, Label의 종류가 2배가 되었다.
    - 1: 걷기, 2: 뛰기, 3: 천천히 걷기, 4: 계단 오르기, 5: 계단 내려가기, 6: 서있기, 7: 앉아있기, 8: 누워있기, 9: 자전거 타기, 10: 서서 자전거 타기, 11: 자전거에 앉아있기
    - 앉아있기 vs 자전거에 앉아있기, 걷기 vs 천천히 걷기를 분류하는 데 디테일이 필요할 듯하다.
- Column들의 종류는 아래와 같다.
    - `timestamp` - 측정 시간
    - `A_x` - 신체부위 'A'에 부착된 센서의 x축 데이터
    - `A_y` - 신체부위 'A'에 부착된 센서의 y축 데이터
    - `A_z` - 신체부위 'A'에 부착된 센서의 z축 데이터
    - `B_x` - 신체부위 'B'에 부착된 센서의 x축 데이터
    - `B_y` - 신체부위 'B'에 부착된 센서의 y축 데이터
    - `B_z` - 신체부위 'B'에 부착된 센서의 z축 데이터
- 신체부위가 어디인지는 알 수 없다. 하지만, 가설을 세워보자면 가장 움직임이 많을 수 있는 **발목과 손목**이지 않을까 생각이 든다. (팔, 다리, 허리)
    - x축: 앞과 뒤 방향으로의 움직임을 측정한다. (천천히 걷기 < 걷기 < 뛰기)
    - y축: 오른쪽과 왼쪽 방향으로의 움직임을 측정한다.
    - z축: 상하 방향으로의 움직임을 측정한다. (계단 내려가기 < 계단 올라가기)
- 분명 A, B는 움직임의 방향이 다른 부위일 것이다. 아래와 같이 동작에 대한 데이터 값을 예측해보았다.
    - 걷기 : x, z축의 움직임이 조금 있다. y축은 거의 없을 것이다.
    - 뛰기 : x, z축의 움직임이 약간 있다. y축은 거의 없을 것이다.
    - 천천히 걷기 : 걷기보다 움직임이 거의 없을 것이다.
    - 계단 오르기 : x, z축의 움직임이 있다. y축은 거의 없을 것이다.
    - 계단 내려가기 : x축은 증가하나, z축은 감소한다. y축은 거의 없을 것이다.
    - 서있기 : x, y, z축 모두 거의 없을 것이다. 하지만, A와 B의 값 차이가 많이 날 것이다.
    - 앉아있기 : x, y, z축 모두 거의 없을 것이다. 하지만, A와 B의 값 차이가 조금 날 것이다.
    - 누워있기 : x, y, z축 모두 거의 없을 것이다. 하지만, A와 B의 값 차이가 거의 없을 것이다.
    - 자전거 타기 : 가장 격한 행동이기 때문에 값이 상대적으로 높을 것이다.
    - 서서 자전거 타기 : 자전거 타기와 유사하지만, A와 B의 값 차이가 조금 더 날 것이다.
    - 자전거에 앉아있기 : 앉아있는 데이터와 유사할 것으로 예상된다.
- 데이터 전처리 계획
    - Feature의 갯수가 7개로 작기 때문에 딱히 제거해야할 필요는 없어보인다.
    - 데이터의 분포도 대부분 정규곡선과 유사한 형태를 띄기 때문에 스케일링을 사용하도록 하자.
    - train 데이터의 결측치는 모두 column 별로 10000개씩이다.(test 데이터는 결측치가 없다)
    - time_stamp는 제거해도 괜찮지 않을까?
    - 유클리드 Norm을 이용하여 해당 크기를 계산하자
        
        ```
        import math
        
        def mag_3_signals(x, y, z):
        	# 유클리드 거리를 저장할 리스트 초기화
        	magnitudes = []
        	
        	# 주어진 세 신호 데이터의 길이 확인 (가정: x, y, z의 길이는 동일하다고 가정)
        	for i in range(len(x)):
        	    # 유클리드 거리 계산 및 결과 리스트에 추가
        	    magnitude = math.sqrt(x[i]**2 + y[i]**2 + z[i]**2)
        	    magnitudes.append(magnitude)
        	
        	# 결과 리스트 반환
        	return magnitudes
        
        ```
        
    - 미분을 통해 변화량(Jerk)를 계산하자 → 이건 불가능하다. 데이터가 시간 순서대로 있지 않고, 순서대로 정렬을 한다고 하더라도 연속하는 동작들의 종류가 다르기 때문이다.
        
        ```
        import numpy as np
        	
        def jerk_one_signal(signal, dt):
        	# 신호의 길이 계산
        	N = len(signal)
        	
        	# 변화율을 저장할 배열 초기화
        	jerk = np.zeros(N-1)
        	
        	# 연속된 두 데이터 포인트 간의 변화율 계산
        	for i in range(N-1):
        	    jerk[i] = (signal[i+1] - signal[i]) / dt
        	
        	# 계산된 변화율 배열 반환
        	return jerk
        ```
        
- Label과 features 간의 상관관계
    - Label    1.000000
    A_x      0.165722
    A_y     -0.275390
    A_z      0.315315
    B_x      0.207724
    B_y      0.065651
    B_z      0.223359
        
        → 그렇게 뚜렷한 데이터는 없는 듯하다. 그나마 z축의 데이터들이 상관관계가 높았다.
        

# 데이터 전처리

1. timestamp column을 삭제한다
2. 결측치의 값을 평균값으로 채운다.
3. 결측치를 삭제한다. (10만개의 데이터 → 53000개의 데이터)
4. 유클리드 Norm을 통하여 A, B 데이터 각각의 Norm 값을 채운다.
5. 모델링 1을 하면서 결과가 너무 처참한 것을 확인할 수 있었다. → timestamp를 버리지 말고, hour, minute, second로 나눠서 실험을 해보자. 늦은 시간에는 자전거를 탈 일이 적고 행동이 작아진다.
6. 그리고 특정 Label의 비율이 불균형이 것을 확인할 수 있었다. → **SMOTE** 라이브러리를 활용하여 Label을 균일한 비율로 만들어주자

# 모델링

1. MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
    1. Accuracy: 0.84765
    2. 앉아있기, 누워있기, 자전거 타기는 0.98정도로 분류를 매우 잘함
    3. 반면, 계단 내려가기는 0.57로 정확도가 매우 떨어지는 모습을 확인할 수 있음(label의 빈도를 확인했을 때, 가장 비율이 낮은 데이터였음. 따라서 불균형으로 인해 성능이 떨어진 것은 아닐까)
    4. 나머지는 0.70 ~ 0.89로 나쁘지 않은 편
    5. 계단 내려가기를 잘 해결해야 결과가 좋을 듯 함
    6. test data의 결과는 0.61848로 좋지는 않다
2. VotingClassifier(RandomForestClassifier, ExtraTreesClassifier, LinearSVC, MLPClassifier)
    1. Accuracy : 0.9679509755582165
    2. 천천히 걷기가 0.82로 정확도가 제일 낮았음
    3. test data의 결과는 **0.96947**로 오히려 더 성능이 좋아진 것을 확인할 수 있었음!
3. StackingClassifier(RandomForestClassifier, ExtraTreesClassifier, MLPClassifier) (LinearSVC는 Voting에서의 성능이 제일 낮아서 제외함. 학습 시간을 줄이기 위해서임)
    1. Accuracy : 0.9929562583644432
    2. Voting에서의 천천히 걷기가 0.82 → 0.99로 매우 상향되었다
    3. test data의 결과는 **0.98919**으로 Voting 모델보다 성능이 좋아졌으나, 과적합이 발생하였다.
4. StackingClassifier(RandomForestClassifier, ExtraTreesClassifier, MLPClassifier, KNeighborsClassifier, XGBClassifier)
    1. Accuracy : 0.9952806931041769
    2. test data의 결과는 **0.99304**으로 이전 모델보다 성능이 좋아졌을 뿐만 아니라, 과적합도 덜 일어난 모습이다.
    3. 추가적으로 다른 모델들을 실험해보고 싶었으나, 학습 시간이 너무 길어서 마감되었다 ㅠ

# 다른 분들은

시간, 분, 초만 나눴던 나와 다르게 밀리 초까지 나누는 분들도 계셨다.

시간 순서대로 정렬하고 보았을 때, 특정 시간 때에 label이 모여있었다.

결측치가 너무 깔끔하게 없어져있다. 인위적으로 낸 것이므로 근처의 비슷한 값을 채워넣었다.

결측치를 선형보간법을 통해서 채웠다.

성능 좋은 하이퍼파라미터를 선택해주는 optuna 라이브러리를 사용하여 하이퍼파라미터를 선택하였다.
