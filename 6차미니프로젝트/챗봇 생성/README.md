# 목표

(월, 화에서는 실습 파일만 작성했기에 따로 메모하지 않았음)

특정 데이터를 사용하여, LLM 모델을 통해 챗봇을 만들자

나무 위키 데이터 학습

# 결과

- Gemma 7bit 모델을 사용했을 때 10개(전체 데이터 56만개 중) 나무위키 문서만 사용했음에도 불구하고 GPU 리소스가 부족한 현상이 나타남.
- Gemma 2bit와 10개의 데이터를 사용해도 결과를 잘 도출하지 못함
- Gemma 2bit와 100개의 데이터를 사용했을 때는 결과를 잘 도출하지 못할 뿐만 아니라, 질문이 두 개를 넘어가면 GPU 부족 오류가 발생함

# 다른 데이터 학습 및 결과

- 뉴스 데이터를 학습
- 나무 위키 모델과 다르게 괜찮은 결과를 답변하는 것을 확인할 수 있었음 → 나무 위키 데이터가 워낙 방대하고 많아서 학습에 어려움을 줬을 것이라고 추측

# 모델 성능 향상을 위한 고찰

- GPT-4와 같이 LLM에서 성능이 가능 좋은 모델의 API 사용
- PostgreSQL의 PG Vector나 ChromaDB와 같은 Vector DB 사용
- CoT(Chain of Thought)와 같은 프롬프트 형식 응용 # 문제에 대한 답을 내기 전에 중간의 논리 과정을 생성하게 하여 복잡한 문제를 처리 가능하도록 분해 → 다단계 과정을 거쳐야 하는 문제를 푸는 사람의 직관적인 생각 과정을 흉내낼 수 있음